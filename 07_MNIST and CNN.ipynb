{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93c9a35a",
   "metadata": {},
   "source": [
    "# MNIST and CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaffa86e",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d92dcd",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d628d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aa6a991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\slcf\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "train_data = dsets.MNIST(root='data/',\n",
    "                         train=True,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "\n",
    "test_data = dsets.MNIST(root='data/',\n",
    "                        train=False,\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d51afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77e6a3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22f6cff94f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAAElCAYAAABgRJorAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAdNklEQVR4nO3de6zdZZkv8OcBxAgIyHgsDchFBTw4gS03EQ3UAQzjJdyGcXoY0MRDzVESxnhQQ3CmHg9ewRlxHBS1AsKIJkyhOuNBAlhmvDQtFZSrReNgYQcELLSgEOh7/uhmLNiud3Wvtfbv3Xt/PknTvdf79F1PFl0P69vf2uvNUkoAAADQra26bgAAAADhDAAAoAnCGQAAQAOEMwAAgAYIZwAAAA0QzgAAABognAEAADRAOGOoMvP7mfn7zFw38evurnsCyMxdMnNxZj6emf+Zmf+j654ANpaZ+0y8hrq8617ojnDGKJxZStlh4td+XTcDEBFfiIinImJORJwaERdl5mu6bQngOb4QEcu7boJuCWcAzGiZuX1EnBwRHymlrCul/EdELImI07rtDGCDzPyriFgTEdd33AodE84YhU9k5kOZ+YPMnNd1M8Cst29EPFNK+flGt90aEa6cAZ3LzB0j4v9ExAe67oXuCWcM24ci4hURsVtEXBwR387MV3bbEjDL7RARjz7vtkcj4sUd9ALwfB+LiK+WUn7ddSN0TzhjqEopy0opa0spT5ZSLo2IH0TEW7ruC5jV1kXEjs+7bceIWNtBLwD/JTPHIuKYiPj7jluhEdt03QAzXomI7LoJYFb7eURsk5n7lFJWTdx2YETc3mFPABER8yJir4i4NzMjNlzp3zoz9y+lHNRhX3QkSyld98AMkZk7R8TrImJpRDwdEe+IDW9tPKiU4iP1gc5k5pWx4R+L/mdEjEXEv0XEEaUUAQ3oTGZuF8+9sv+/Y0NY+1+llN900hSdcuWMYXpBRPzfiHh1RDwTEXdFxAmCGdCA90bEooh4MCIejg0vfAQzoFOllCci4olnv8/MdRHxe8Fs9nLlDAAAoAE+EAQAAKABwhkAAEADhDMAAIAGCGcAAAANEM4AAAAaMKUfpZ+ZPhoSZqBSyrQ+aNxsghnroVLKf+u6iUGYTzAzbe6100BXzjLzuMy8OzPvycwPD7IXwDCZT0BE/GfXDTyf2QT0MulwlplbR8QXIuLPI2L/iJifmfsPqzGAyTKfgBaZTUDNIFfODouIe0opvyylPBURV0bE8cNpC2Ag5hPQIrMJ6GmQcLZbRPx6o+9XT9z2HJm5IDNXZOaKAe4LYEtU55PZBHTAayegp0E+EGRTP8T2Rz+0Wkq5OCIujvBDrcCUqc4nswnogNdOQE+DXDlbHREv3+j73SPi/sHaARgK8wlokdkE9DRIOFseEftk5t6ZuW1E/FVELBlOWwADMZ+AFplNQE+TfltjKeXpzDwzIq6NiK0jYlEp5fahdQYwSeYT0CKzCajJUqburczeNw0zk0OogUbdXEo5pOsmBmE+wcw0kkOoAQAAGA7hDAAAoAHCGQAAQAOEMwAAgAYIZwAAAA0QzgAAABognAEAADRAOAMAAGiAcAYAANAA4QwAAKABwhkAAEADhDMAAIAGCGcAAAANEM4AAAAaIJwBAAA0QDgDAABogHAGAADQAOEMAACgAcIZAABAA4QzAACABghnAAAADRDOAAAAGiCcAQAANEA4AwAAaMA2XTcAAC05+OCDqzVnnnlmteb000+v1lx22WXVms9//vM911euXFndA4DpwZUzAACABghnAAAADRDOAAAAGiCcAQAANEA4AwAAaIBwBgAA0ADhDAAAoAHCGQAAQAOylDJ1d5Y5dXfGpG299dbVmp122mkKOunvoNftttuuWrPffvtVa973vvf1XD///POre8yfP79a8/vf/75a88lPfrJa89GPfrRaM1VKKdl1D4Mwm2aPsbGxas0NN9xQrdlxxx2H0E1/Hn300Z7rf/InfzJFnUxLN5dSDum6iUGYT0xnRx99dLXmiiuuqNYcddRR1Zq77767r55asbnXTq6cAQAANGCbQf5wZv4qItZGxDMR8fR0/9cpYOYwn4AWmU1ALwOFswlvKqU8NIR9AIbNfAJaZDYBm+RtjQAAAA0YNJyViPheZt6cmQs2VZCZCzJzRWauGPC+ALZEz/lkNgEd8doJ2KxB39b4hlLK/Zn5soi4LjPvKqXctHFBKeXiiLg4wicOAVOq53wym4COeO0EbNZAV85KKfdP/P5gRCyOiMOG0RTAoMwnoEVmE9DLpMNZZm6fmS9+9uuIeHNE3DasxgAmy3wCWmQ2ATWDvK1xTkQszsxn9/nnUsr/G0pXs9Aee+zRc33bbbet7nHEEUdUa974xjdWa3beeedqzcknn1ytacnq1aurNRdeeGHP9RNPPLG6x9q1a6s1t956a7Vm6dKl1Rp6Mp9mqcMO630R4qqrrqrusdNOO1VrSqm/06yfefDUU09Va2qHTB9++OHVPVauXDmUXhjYtJ5NRx55ZLWmn0PRFy9ePIx2mAYOPfTQas3y5cunoJPpY9LhrJTyy4g4cIi9AAyF+QS0yGwCanyUPgAAQAOEMwAAgAYIZwAAAA0QzgAAABognAEAADRAOAMAAGiAcAYAANCAQQ6hpk9jY2PVmhtuuKHnej+Hos5W69evr9ace+651Zp169b1XL/iiiuqe4yPj1drfvvb31Zr7r777moNzCTbbbddteaggw6q1lx++eU91+fOndt3T4NatWpVtebTn/50tebKK6/suf6DH/ygukc/M/ATn/hEtYbZbd68edWaffbZp1rjEOqZY6utel/n2Xvvvat77LnnntWaiYPbZwVXzgAAABognAEAADRAOAMAAGiAcAYAANAA4QwAAKABwhkAAEADhDMAAIAGCGcAAAANcAj1FLj33nurNQ8//HDP9el2CPWyZcuqNWvWrKnWvOlNb6rWPPXUU9War3/969UaoDtf+tKXqjXz58+fgk6Gp59Ds3fYYYdqzdKlS3uu93Mw8AEHHFCtgZrTTz+9WvOjH/1oCjqhFXPnzu25fsYZZ1T3uPzyy6s1d911V989TXeunAEAADRAOAMAAGiAcAYAANAA4QwAAKABwhkAAEADhDMAAIAGCGcAAAANcM7ZFHjkkUeqNWeffXbP9be97W3VPX7yk59Uay688MJqTT9uueWWnuvHHntsdY/HH3+8WvOa17ymWnPWWWdVa4DuHHzwwdWat771rdWazBy4l9qZYRER3/72t6s1559/frXm/vvvr9b0M7d/+9vf9lz/sz/7s+oew3jsYKut/Js+z/WVr3xl4D1WrVo1hE5mDs8yAACABghnAAAADRDOAAAAGiCcAQAANEA4AwAAaIBwBgAA0ADhDAAAoAHCGQAAQAMcQt2Iq6++uuf6DTfcUN1j7dq11ZoDDzywWvPud7+7WlM7gLWfA6b7cfvtt1drFixYMJT7Arbc2NhYtea6666r1uy4447VmlJKtea73/1uz/X58+dX9zjqqKOqNeeee261pp/DWX/zm99Ua2699dae6+vXr6/u0c8h3wcddFC1ZuXKldUapqcDDjigWjNnzpwp6ITpZKeddhp4j37+HzGbuHIGAADQgGo4y8xFmflgZt620W27ZOZ1mblq4veXjLZNgD9mPgEtMpuAyernytklEXHc8277cERcX0rZJyKun/geYKpdEuYT0J5LwmwCJqEazkopN0XEI8+7+fiIuHTi60sj4oThtgVQZz4BLTKbgMma7AeCzCmljEdElFLGM/NlmyvMzAUR4RMbgKnS13wym4Ap5rUTUDXyT2sspVwcERdHRGRm/aO2AKaA2QS0ynyC2Wuyn9b4QGbOjYiY+P3B4bUEMBDzCWiR2QRUTTacLYmId058/c6IuGY47QAMzHwCWmQ2AVXVtzVm5jciYl5EvDQzV0fE30XEJyPiW5n57oi4NyJOGWWTRDz22GND2efRRx8dyj5nnHFGz/VvfvOb1T36OTgVejGfRm/fffftuX722WdX9+jnkNKHHnqoWjM+Pl6tufTSS3uur1u3rrrHv/7rvw6lpiUvetGLqjUf+MAHqjWnnnrqMNqZ8abjbHrLW95Srenn7xEzRz+Hju+9994D389999038B4zSTWclVLmb2bp6CH3ArBFzCegRWYTMFmTfVsjAAAAQyScAQAANEA4AwAAaIBwBgAA0ADhDAAAoAHCGQAAQAOEMwAAgAZUzzljZlm4cGG15uCDD67WHHXUUT3XjznmmOoe3/ve96o1wOi88IUvrNacf/75Pdf7Obh27dq11ZrTTz+9WrNixYpqjUNyJ2+PPfbougU6tN9++w1ln9tvv30o+9C92vyPqB9U/fOf/7y6Rz//j5hNXDkDAABogHAGAADQAOEMAACgAcIZAABAA4QzAACABghnAAAADRDOAAAAGiCcAQAANMAh1LPM448/Xq0544wzqjUrV67suf7lL3+5useNN95Yrenn0NkvfOEL1ZpSSrUGZpvXvva11Zp+DpmuOf7446s1S5cuHfh+gO4tX7686xZmtB133LFac9xxx1Vr/vqv/7pa8+Y3v7mvnnr52Mc+Vq1Zs2bNwPczk7hyBgAA0ADhDAAAoAHCGQAAQAOEMwAAgAYIZwAAAA0QzgAAABognAEAADTAOWf8kV/84hfVmne9610917/2ta9V9zjttNOGUrP99ttXay677LJqzfj4eLUGZpLPfvaz1ZrM7Lnez/lkzjAbra22qv876/r166egE4jYZZddum7hvxx44IHVmtqMi4g45phjqjW77757tWbbbbftuX7qqadW9+jn+f673/2uWrNs2bJqzZNPPlmt2Wab3lHi5ptvru7Bc7lyBgAA0ADhDAAAoAHCGQAAQAOEMwAAgAYIZwAAAA0QzgAAABognAEAADRAOAMAAGiAQ6iZlMWLF/dcX7VqVXWPfg7APfroo6s1H//4x6s1e+65Z7XmvPPO67l+3333VfeAVrztbW+r1oyNjVVrSik915csWdJvS4xIPwdM1/47RkTccsstQ+iG6aqfg4v7+Xv0xS9+sVpzzjnn9NXToA444IBqTT+HUD/99NPVmieeeKJac8cdd/RcX7RoUXWPFStWVGuWLl1arXnggQeqNatXr67WvOhFL+q5ftddd1X34LmqV84yc1FmPpiZt21028LMvC8zb5n49ZbRtgnwx8wnoEVmEzBZ/byt8ZKIOG4Tt/99KWVs4te/DbctgL5cEuYT0J5LwmwCJqEazkopN0XEI1PQC8AWMZ+AFplNwGQN8oEgZ2bmTycu3b9kaB0BDM58AlpkNgE9TTacXRQRr4yIsYgYj4gLNleYmQsyc0Vm1n+CEWBwfc0nswmYYl47AVWTCmellAdKKc+UUtZHxJcj4rAetReXUg4ppRwy2SYB+tXvfDKbgKnktRPQj0mFs8ycu9G3J0bEbZurBZhK5hPQIrMJ6Ef1nLPM/EZEzIuIl2bm6oj4u4iYl5ljEVEi4lcR8Z7RtQiwaeYT0CKzCZis7OdAwaHdWebU3RnN23nnnas1b3/726s1X/va16o1/RwyecMNN/RcP/bYY6t7zFallPoD3LCZOJtOOeWUas03vvGNas2DDz7Yc/3ggw+u7jE+Pl6tma1e+MIXVmsWLlzYc/2DH/xgdY/rr7++WnPSSSdVa9atW1etaczN0/2tgS3Npw996EPVmiOOOGIKOhmeq6++ulpz5513Vmt+/OMfD6GbqbNgwYJqTT8Hiv/yl7/suf6qV72q755mm829dhrk0xoBAAAYEuEMAACgAcIZAABAA4QzAACABghnAAAADRDOAAAAGiCcAQAANEA4AwAAaMA2XTfA7LVmzZpqzde//vVqzVe+8pVqzTbb1P+qH3nkkT3X582bV93j+9//frUGppMnn3yy57oDpjevnwOmzz333GrN2Wef3XN99erV1T0uuOCCas00PGCaKfapT32q6xYYkqOPPnoo+1x11VVD2Yc/cOUMAACgAcIZAABAA4QzAACABghnAAAADRDOAAAAGiCcAQAANEA4AwAAaIBwBgAA0ACHUDMSBxxwQLXmL/7iL6o1hx56aLWmnwOm+3HHHXf0XL/pppuGcj8wnSxZsqTrFpo0NjZWrakdHh0R8Y53vKNac8011/RcP/nkk6t7AIzC4sWLu25hxnHlDAAAoAHCGQAAQAOEMwAAgAYIZwAAAA0QzgAAABognAEAADRAOAMAAGiAcAYAANAAh1DzR/bbb79qzZlnntlz/aSTTqruseuuu/bd06CeeeaZas34+HjP9fXr1w+rHRi5zBxKzQknnNBz/ayzzuq3pWnj/e9/f7XmIx/5SLVmp512qtZcccUV1ZrTTz+9WgPAzODKGQAAQAOEMwAAgAYIZwAAAA0QzgAAABognAEAADRAOAMAAGiAcAYAANAA55zNIP2cGzZ//vxqTe0Ms4iIvfbaq5+WpsSKFSuqNeedd161ZsmSJcNoB5pQShlKTW2uXHjhhdU9Fi1aVK15+OGHqzWHH354tea0007ruX7ggQdW99h9992rNffee2+15tprr63W/NM//VO1BqAL/ZyFue+++/Zc//GPfzysdmaN6pWzzHx5Zt6YmXdm5u2ZedbE7btk5nWZuWri95eMvl2ADcwmoFXmEzBZ/byt8emI+EAp5b9HxOER8b7M3D8iPhwR15dS9omI6ye+B5gqZhPQKvMJmJRqOCuljJdSVk58vTYi7oyI3SLi+Ii4dKLs0og4YUQ9AvwRswlolfkETNYWfSBIZu4VEa+NiGURMaeUMh6xYQhFxMuG3h1AH8wmoFXmE7Al+v5AkMzcISKuioi/KaU81s8PCU78uQURsWBy7QH0ZjYBrTKfgC3V15WzzHxBbBguV5RS/mXi5gcyc+7E+tyIeHBTf7aUcnEp5ZBSyiHDaBjgWWYT0CrzCZiMfj6tMSPiqxFxZynlsxstLYmId058/c6IuGb47QFsmtkEtMp8Aiarn7c1viEiTouIn2XmLRO3nRMRn4yIb2XmuyPi3og4ZSQdAmya2QS0ynwCJqUazkop/xERm3uT9NHDbWf2mjNnTs/1/fffv7rHP/7jP1ZrXv3qV/fd06gtW7asWvOZz3ymWnPNNfV/eFy/fn1fPTF9mE1TY+utt+65/t73vre6x8knn1yteeyxx6o1++yzT7VmGH74wx9Wa2688cZqzd/+7d8Oox2mIfOJmaCUUq3Zaqst+mxB+uARBQAAaIBwBgAA0ADhDAAAoAHCGQAAQAOEMwAAgAYIZwAAAA0QzgAAABognAEAADSgegg1ve2yyy7Vmi996UvVmrGxsZ7rr3jFK/ptaUrUDmm94IILqntce+211Zrf/e53ffcE/MGPfvSjas3y5curNYceeujAvey6667Vmjlz5gx8PxERDz/8cM/1K6+8srrHWWedNZReAGa617/+9T3XL7nkkqlpZAZx5QwAAKABwhkAAEADhDMAAIAGCGcAAAANEM4AAAAaIJwBAAA0QDgDAABogHAGAADQgFl7CPXrXve6as3ZZ59drTnssMOqNbvttltfPU2FJ554olpz4YUXVms+/vGP91x//PHH++4JGL7Vq1dXa0466aRqzXve856e6+eee27fPQ3qc5/7XLXmoosu6rl+zz33DKsdgBktM7tuYVZy5QwAAKABwhkAAEADhDMAAIAGCGcAAAANEM4AAAAaIJwBAAA0QDgDAABogHAGAADQgFl7CPWJJ544lJphueOOO3quf+c736nu8fTTT1drLrjggmrNmjVrqjXA9Dc+Pl6tWbhw4UDrALTnu9/9brXmlFNOmYJOeD5XzgAAABognAEAADRAOAMAAGiAcAYAANAA4QwAAKABwhkAAEADhDMAAIAGCGcAAAANyFJK74LMl0fEZRGxa0Ssj4iLSymfy8yFEXFGRPxmovScUsq/VfbqfWfAtFRKyam+T7MJ6MPNpZRDpvpOzSegZnOvnfoJZ3MjYm4pZWVmvjgibo6IEyLiLyNiXSnl/H6bMGBgZuoonJlNQE1X4cx8Anra3Gunbfr4g+MRMT7x9drMvDMidhtuewBbxmwCWmU+AZO1RT9zlpl7RcRrI2LZxE1nZuZPM3NRZr5k2M0B9MNsAlplPgFbou9wlpk7RMRVEfE3pZTHIuKiiHhlRIzFhn8dumAzf25BZq7IzBWDtwvwXGYT0CrzCdhS1Z85i4jIzBdExHci4tpSymc3sb5XRHynlPKnlX28bxpmoC5+5izCbAKqOvmZswjzCehtc6+dqlfOMjMj4qsRcefGw2Xih12fdWJE3DZokwD9MpuAVplPwGT182mNb4yIf4+In8WGj4ONiDgnIubHhsvyJSJ+FRHvmfgB2F57+dcfmIE6+rRGswmo6erTGs0noKdJf5T+MBkwMDN19bbGYTGbYMbq7G2Nw2I+wcw06bc1AgAAMHrCGQAAQAOEMwAAgAYIZwAAAA0QzgAAABognAEAADRAOAMAAGiAcAYAANAA4QwAAKABwhkAAEADhDMAAIAGCGcAAAANEM4AAAAaIJwBAAA0QDgDAABogHAGAADQAOEMAACgAdtM8f09FBH/udH3L524bbrQ72jpd7RG1e+eI9hzqj1/NkX47ztq+h0t/W4wE+eT/7ajpd/R0u8Gm51NWUoZwf31JzNXlFIO6ayBLaTf0dLvaE23frs23R4v/Y6WfkdruvXbpen2WOl3tPQ7Wl30622NAAAADRDOAAAAGtB1OLu44/vfUvodLf2O1nTrt2vT7fHS72jpd7SmW79dmm6PlX5HS7+jNeX9dvozZwAAAGzQ9ZUzAAAAosNwlpnHZebdmXlPZn64qz76lZm/ysyfZeYtmbmi636eLzMXZeaDmXnbRrftkpnXZeaqid9f0mWPG9tMvwsz876Jx/iWzHxLlz1uLDNfnpk3ZuadmXl7Zp41cXuTj3GPfpt9jFthNg2X2TRaZtPsYj4Nl/k0OmbTAL108bbGzNw6In4eEcdGxOqIWB4R80spd0x5M33KzF9FxCGllCbPZsjMIyNiXURcVkr504nbPh0Rj5RSPjkxxF9SSvlQl30+azP9LoyIdaWU87vsbVMyc25EzC2lrMzMF0fEzRFxQkS8Kxp8jHv0+5fR6GPcArNp+Mym0TKbZg/zafjMp9Exmyavqytnh0XEPaWUX5ZSnoqIKyPi+I56mRFKKTdFxCPPu/n4iLh04utLY8NfsiZspt9mlVLGSykrJ75eGxF3RsRu0ehj3KNfejObhsxsGi2zaVYxn4bMfBods2nyugpnu0XErzf6fnW0P5xLRHwvM2/OzAVdN9OnOaWU8YgNf+ki4mUd99OPMzPzpxOX7pu41P18mblXRLw2IpbFNHiMn9dvxDR4jDtkNk2N5p83m9D888ZsmvHMp6nR/HNnE5p+7phNW6arcJabuK31j418QynloIj484h438SlZYbrooh4ZUSMRcR4RFzQaTebkJk7RMRVEfE3pZTHuu6nZhP9Nv8Yd8xsYlOaf96YTbOC+cSmNP3cMZu2XFfhbHVEvHyj73ePiPs76qUvpZT7J35/MCIWx4a3F7TugYn30D77XtoHO+6np1LKA6WUZ0op6yPiy9HYY5yZL4gNT9grSin/MnFzs4/xpvpt/TFugNk0NZp93mxK688bs2nWMJ+mRrPPnU1p+bljNk1OV+FseUTsk5l7Z+a2EfFXEbGko16qMnP7iR8OjMzcPiLeHBG39f5TTVgSEe+c+PqdEXFNh71UPftknXBiNPQYZ2ZGxFcj4s5Symc3WmryMd5cvy0/xo0wm6ZGk8+bzWn5eWM2zSrm09Ro8rmzOa0+d8ymAXrp6hDq3PBRlP8QEVtHxKJSynmdNNKHzHxFbPgXn4iIbSLin1vrNzO/ERHzIuKlEfFARPxdRFwdEd+KiD0i4t6IOKWU0sQPkm6m33mx4bJxiYhfRcR7nn1fctcy840R8e8R8bOIWD9x8zmx4f3IzT3GPfqdH40+xq0wm4bLbBots2l2MZ+Gy3waHbNpgF66CmcAAAD8QWeHUAMAAPAHwhkAAEADhDMAAIAGCGcAAAANEM4AAAAaIJwBAAA0QDgDAABogHAGAADQgP8PGKGn6orMnHwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (15, 5))\n",
    "ax1 = fig.add_subplot(1, 3, 1)\n",
    "ax2 = fig.add_subplot(1, 3, 2)\n",
    "ax3 = fig.add_subplot(1, 3, 3)\n",
    "\n",
    "ax1.set_title(train_data.targets[0].item())\n",
    "ax1.imshow(train_data.data[0,:,:].numpy(), cmap='gray')\n",
    "\n",
    "ax2.set_title(train_data.targets[1].item())\n",
    "ax2.imshow(train_data.data[1,:,:].numpy(), cmap='gray')\n",
    "\n",
    "ax3.set_title(train_data.targets[2].item())\n",
    "ax3.imshow(train_data.data[2,:,:].numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b8b336",
   "metadata": {},
   "source": [
    "### Make Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e95b39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18300698",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_data,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9906ad86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 8 2 6 4 1 0 0 9 1 8 8 5 8 3 8 0 3 2 0 2 0 4 4 4 9 3 0 9 6 8 0 0 2 5 8 4\n",
      " 5 7 4 2 3 3 0 0 7 7 2 1 0 1 4 5 4 8 9 3 5 1 7 8 2 2 0 4 0 6 5 2 7 3 8 8 1\n",
      " 8 6 2 5 9 3 7 3 9 2 4 2 2 1 8 0 6 7 6 6 6 0 5 0 7 9] ,  100\n"
     ]
    }
   ],
   "source": [
    "batch_images, batch_labels = iter(train_loader).next()\n",
    "print(batch_labels.numpy(), \", \", len(batch_labels.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8827893",
   "metadata": {},
   "source": [
    "## Train & Evaluate MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cde575",
   "metadata": {},
   "source": [
    "### Train MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfdc19e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6197d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "# def cross_entropy(input, target, weight=None, size_average=True, ignore_index=-100, reduce=True):\n",
    "\n",
    "# Args:\n",
    "#     input: Variable :math:`(N, C)` where `C = number of classes`\n",
    "#     target: Variable :math:`(N)` where each value is\n",
    "#         `0 <= targets[i] <= C-1`\n",
    "#     weight (Tensor, optional): a manual rescaling weight given to each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75bb698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1323c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5db1019f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], lter [300/600], Loss: 2.2238\n",
      "Epoch [1/5], lter [600/600], Loss: 2.1512\n",
      "Epoch [2/5], lter [300/600], Loss: 2.0402\n",
      "Epoch [2/5], lter [600/600], Loss: 1.9955\n",
      "Epoch [3/5], lter [300/600], Loss: 1.8974\n",
      "Epoch [3/5], lter [600/600], Loss: 1.8218\n",
      "Epoch [4/5], lter [300/600], Loss: 1.6634\n",
      "Epoch [4/5], lter [600/600], Loss: 1.5709\n",
      "Epoch [5/5], lter [300/600], Loss: 1.4701\n",
      "Epoch [5/5], lter [600/600], Loss: 1.4216\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    total_batch = len(train_data) // batch_size\n",
    "    \n",
    "    for i, (batch_images, batch_labels) in enumerate(train_loader):\n",
    "        \n",
    "        X = batch_images.view(-1, 28 * 28)\n",
    "        Y = batch_labels\n",
    "        \n",
    "        pre = model(X)\n",
    "        cost = loss(pre, Y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 300 == 0:\n",
    "            print('Epoch [%d/%d], lter [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, total_batch, cost.item()))\n",
    "    \n",
    "print(\"Learning Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3645806",
   "metadata": {},
   "source": [
    "### Evaluate MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2be8a319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test images: 79.870000 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for images, labels in test_data:\n",
    "    \n",
    "    images  = images.view(-1, 28 * 28)\n",
    "    outputs = model(images)\n",
    "    \n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    total += 1\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy of test images: %f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8b30d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "r = random.randint(0, len(test_data)-1)\n",
    "X_single_data = test_data.data[r:r + 1].view(-1,28*28).float()\n",
    "Y_single_data = test_data.targets[r:r + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8fb3fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label :  [0]\n",
      "Prediction :  [0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "single_pre = model(X_single_data)\n",
    "plt.imshow(X_single_data.data.view(28,28).numpy(), cmap='gray')\n",
    "\n",
    "print('Label : ', Y_single_data.data.view(1).numpy())\n",
    "print('Prediction : ', torch.max(single_pre.data, 1)[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7451c1f9",
   "metadata": {},
   "source": [
    "## Train & Evaluate CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4011175",
   "metadata": {},
   "source": [
    "### Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45056499",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64*3*3, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 10)\n",
    "        )       \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.conv_layer(x)\n",
    "        out = out.view(-1,64*3*3)\n",
    "        out = self.fc_layer(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51787254",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a052fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a862c372",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60d2287e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], lter [300/600], Loss: 1.7904\n",
      "Epoch [1/3], lter [600/600], Loss: 0.3767\n",
      "Epoch [2/3], lter [300/600], Loss: 0.2303\n",
      "Epoch [2/3], lter [600/600], Loss: 0.1229\n",
      "Epoch [3/3], lter [300/600], Loss: 0.1896\n",
      "Epoch [3/3], lter [600/600], Loss: 0.2204\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    total_batch = len(train_data) // batch_size\n",
    "\n",
    "    for i, (batch_images, batch_labels) in enumerate(train_loader):\n",
    "\n",
    "        X = batch_images.cuda()\n",
    "        Y = batch_labels.cuda()\n",
    "\n",
    "        pre = model(X)\n",
    "        cost = loss(pre, Y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 300 == 0:\n",
    "            print('Epoch [%d/%d], lter [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, total_batch, cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec4db40",
   "metadata": {},
   "source": [
    "### Evaulate CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecaf3248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test images: 96.320000 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    \n",
    "    images = images.cuda()\n",
    "    outputs = model(images)\n",
    "    \n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels.cuda()).sum()\n",
    "    \n",
    "print('Accuracy of test images: %f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72bd649",
   "metadata": {},
   "source": [
    "## Save and Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6ccb34",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73caab06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\slcf\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, \"sample1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20bf748c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"sample2.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed882f15",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c860808a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv_layer): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Linear(in_features=1600, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(\"sample1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6c4f72e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'CNN' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f746249377f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Class가 변경되거나 없어지면 무조건 에러 발생\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mCNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sample1.pth\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'CNN' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "# Class가 변경되거나 없어지면 무조건 에러 발생\n",
    "del CNN\n",
    "torch.load(\"sample1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cde79e9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv_layer.0.weight',\n",
       "              tensor([[[[-0.0990,  0.1003,  0.0784, -0.0463,  0.0550],\n",
       "                        [ 0.0777,  0.0056, -0.0169,  0.0741,  0.0613],\n",
       "                        [-0.1140, -0.0130, -0.0947,  0.0434,  0.0541],\n",
       "                        [ 0.0888, -0.1151, -0.0670, -0.0473,  0.1092],\n",
       "                        [-0.0753, -0.0176, -0.0103, -0.0004,  0.0531]],\n",
       "              \n",
       "                       [[ 0.0235, -0.1059, -0.1046,  0.0692, -0.0182],\n",
       "                        [-0.0098,  0.0274, -0.0665, -0.0386, -0.0824],\n",
       "                        [-0.0674, -0.0335, -0.0380, -0.0557,  0.1107],\n",
       "                        [-0.1061,  0.0850, -0.0545,  0.0390, -0.0513],\n",
       "                        [-0.0689,  0.0334, -0.0873, -0.0368,  0.0655]],\n",
       "              \n",
       "                       [[-0.0539, -0.1048,  0.0259, -0.0206,  0.0901],\n",
       "                        [ 0.1142,  0.0408,  0.0435, -0.0873,  0.0765],\n",
       "                        [-0.0734,  0.0803,  0.0538,  0.0710,  0.1020],\n",
       "                        [-0.0207,  0.0800,  0.1077, -0.1058, -0.1082],\n",
       "                        [ 0.0397, -0.0372, -0.1021, -0.0999,  0.0889]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1053,  0.0662,  0.0728, -0.0090,  0.1119],\n",
       "                        [-0.0364,  0.0503,  0.0915, -0.0456, -0.0891],\n",
       "                        [-0.0681, -0.1084, -0.0264, -0.1070,  0.0149],\n",
       "                        [-0.1086, -0.0473, -0.0764,  0.0913,  0.0212],\n",
       "                        [-0.0038, -0.0444,  0.0438,  0.0525,  0.0082]],\n",
       "              \n",
       "                       [[ 0.0554, -0.0215,  0.1135, -0.0269, -0.0119],\n",
       "                        [-0.0022,  0.0020,  0.0585, -0.0957, -0.1061],\n",
       "                        [ 0.0919,  0.0428, -0.0648,  0.1046,  0.0540],\n",
       "                        [ 0.0662, -0.0009,  0.0712,  0.1116,  0.0613],\n",
       "                        [-0.0601,  0.1052, -0.0517,  0.1112,  0.0822]],\n",
       "              \n",
       "                       [[-0.0234,  0.0590, -0.0015, -0.0424, -0.1045],\n",
       "                        [ 0.1133, -0.0399,  0.0289, -0.0309,  0.0930],\n",
       "                        [ 0.0463,  0.0462,  0.0724, -0.0608,  0.0494],\n",
       "                        [-0.0215,  0.0730,  0.0421,  0.0851,  0.0508],\n",
       "                        [ 0.0687,  0.0133, -0.0248, -0.0405,  0.0616]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0279, -0.0159,  0.0167,  0.0243, -0.0515],\n",
       "                        [ 0.0783, -0.0913, -0.0693,  0.1045,  0.0511],\n",
       "                        [ 0.0325,  0.0365,  0.0144,  0.0484,  0.1062],\n",
       "                        [ 0.0244, -0.0805,  0.0393, -0.0831,  0.0080],\n",
       "                        [ 0.0632,  0.0236,  0.0010, -0.0146, -0.0210]],\n",
       "              \n",
       "                       [[-0.1092, -0.0785,  0.0997, -0.0392, -0.0173],\n",
       "                        [ 0.0214,  0.1147,  0.1105, -0.0643,  0.0328],\n",
       "                        [ 0.0933,  0.1005,  0.0434, -0.0351, -0.0134],\n",
       "                        [ 0.0072, -0.0921,  0.0385, -0.0010, -0.0402],\n",
       "                        [ 0.0973, -0.0924,  0.0010,  0.0748, -0.1103]],\n",
       "              \n",
       "                       [[-0.0261,  0.0641, -0.0133, -0.1144,  0.1001],\n",
       "                        [ 0.0633,  0.0247,  0.0792,  0.1135,  0.0857],\n",
       "                        [-0.0510,  0.0229,  0.1049, -0.0453, -0.0639],\n",
       "                        [ 0.0798, -0.0817,  0.0183, -0.0115,  0.1152],\n",
       "                        [ 0.0209,  0.0560, -0.0138,  0.0174,  0.0450]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0875, -0.0941,  0.0210, -0.0054,  0.0047],\n",
       "                        [-0.0429, -0.0267, -0.0576, -0.0507, -0.0600],\n",
       "                        [ 0.1072,  0.0381, -0.0617, -0.1020, -0.1111],\n",
       "                        [-0.0933, -0.0627, -0.0128, -0.0666,  0.0333],\n",
       "                        [ 0.0320, -0.0792, -0.0630, -0.0187,  0.0129]],\n",
       "              \n",
       "                       [[-0.1004,  0.0386,  0.0075, -0.1134, -0.0244],\n",
       "                        [-0.0338,  0.0946, -0.0935,  0.0444,  0.0458],\n",
       "                        [-0.0072,  0.1108,  0.1065, -0.1144,  0.0627],\n",
       "                        [ 0.0044, -0.0079, -0.0874,  0.0316, -0.0681],\n",
       "                        [ 0.0839,  0.0961,  0.1099, -0.0120, -0.0192]],\n",
       "              \n",
       "                       [[-0.0806,  0.0759, -0.0456,  0.0095,  0.0685],\n",
       "                        [-0.0845, -0.0931, -0.0613,  0.0885,  0.0175],\n",
       "                        [ 0.0302,  0.0857,  0.0605,  0.0609,  0.0948],\n",
       "                        [ 0.1080,  0.0136, -0.0647, -0.0303, -0.0539],\n",
       "                        [ 0.0769,  0.0609, -0.0117, -0.0282,  0.0995]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0395,  0.0176, -0.0868, -0.0618,  0.0690],\n",
       "                        [-0.0967, -0.0939,  0.0476, -0.0084,  0.0168],\n",
       "                        [ 0.0618,  0.0450,  0.0026, -0.0316, -0.0224],\n",
       "                        [ 0.0233,  0.1074,  0.0356, -0.0548, -0.0683],\n",
       "                        [ 0.0018, -0.0089,  0.0925, -0.0095,  0.0057]],\n",
       "              \n",
       "                       [[-0.1002,  0.0481,  0.0177, -0.0494, -0.0318],\n",
       "                        [-0.1001, -0.1109,  0.1011, -0.0668, -0.0013],\n",
       "                        [-0.0206, -0.0807, -0.0783,  0.0926,  0.0799],\n",
       "                        [-0.0382,  0.0896, -0.0922,  0.0377,  0.0129],\n",
       "                        [ 0.0814, -0.0916,  0.0654, -0.0769, -0.0530]],\n",
       "              \n",
       "                       [[ 0.0999,  0.0916, -0.0769, -0.0876, -0.0510],\n",
       "                        [-0.0544,  0.0269, -0.0396, -0.0627,  0.0401],\n",
       "                        [-0.0415,  0.1061, -0.0935,  0.1099, -0.0438],\n",
       "                        [-0.0634, -0.1119,  0.0967,  0.0186, -0.1007],\n",
       "                        [ 0.0284, -0.0866,  0.0966,  0.0277, -0.0386]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0552, -0.0589,  0.0516, -0.0161,  0.1131],\n",
       "                        [-0.0776,  0.0267, -0.0925,  0.0967,  0.0420],\n",
       "                        [-0.1107,  0.0171, -0.0438, -0.0064, -0.0331],\n",
       "                        [-0.0482, -0.0605,  0.0809, -0.0794, -0.0343],\n",
       "                        [ 0.0703,  0.0217, -0.0848,  0.0768,  0.0561]],\n",
       "              \n",
       "                       [[-0.0486,  0.0640,  0.0212,  0.0351,  0.1137],\n",
       "                        [-0.0217, -0.0292, -0.0986, -0.0447,  0.0905],\n",
       "                        [-0.0296,  0.0726, -0.0972,  0.1053, -0.0291],\n",
       "                        [-0.0250, -0.1136,  0.0671, -0.0942, -0.0218],\n",
       "                        [-0.0997, -0.0141,  0.0239,  0.0544,  0.0488]],\n",
       "              \n",
       "                       [[-0.0095, -0.0707,  0.1109, -0.0995, -0.0549],\n",
       "                        [-0.0524, -0.0271,  0.1042,  0.0786, -0.0527],\n",
       "                        [-0.1024,  0.1020,  0.0388, -0.0735,  0.0131],\n",
       "                        [ 0.0925,  0.0003, -0.0204,  0.0235,  0.0143],\n",
       "                        [ 0.1029, -0.0452, -0.0399, -0.0450, -0.0082]]]], device='cuda:0')),\n",
       "             ('conv_layer.0.bias',\n",
       "              tensor([-0.0249,  0.0185, -0.0377,  0.0669, -0.0255, -0.1074,  0.0971,  0.0255,\n",
       "                       0.0407,  0.0974,  0.0254,  0.0747,  0.0623,  0.0602,  0.0702,  0.0137,\n",
       "                      -0.0608, -0.0919, -0.1103,  0.0534,  0.0411, -0.0074, -0.0850,  0.1111,\n",
       "                      -0.1119,  0.0735,  0.0526,  0.0629, -0.1053,  0.1090, -0.1074,  0.0320],\n",
       "                     device='cuda:0')),\n",
       "             ('conv_layer.3.weight',\n",
       "              tensor([[[[ 1.5973e-02, -6.5206e-03, -1.8268e-02,  2.9672e-03,  1.0650e-02],\n",
       "                        [ 1.3887e-02,  3.2554e-02, -2.3318e-02, -2.5437e-02, -4.7766e-03],\n",
       "                        [-2.2080e-02,  5.4039e-03,  1.2646e-02,  3.1241e-02,  1.0565e-02],\n",
       "                        [-5.6295e-03,  3.2156e-02, -2.5730e-03,  1.1785e-02,  1.4475e-02],\n",
       "                        [-3.2010e-02, -1.0515e-02, -2.6198e-04,  2.6556e-02, -2.2382e-02]],\n",
       "              \n",
       "                       [[-3.3145e-02, -1.5841e-03, -3.0878e-02,  2.4355e-02, -2.9021e-02],\n",
       "                        [-3.3915e-02, -3.5050e-02,  3.0611e-02, -1.2667e-02, -3.3256e-02],\n",
       "                        [-1.7102e-02, -1.5427e-02,  2.6095e-02,  2.0019e-02, -2.4353e-02],\n",
       "                        [-2.3112e-02,  3.5225e-02, -2.4315e-02, -2.0213e-02, -2.7511e-02],\n",
       "                        [ 3.2182e-03,  2.3085e-03, -2.6728e-02, -2.8899e-02, -6.9139e-03]],\n",
       "              \n",
       "                       [[ 1.3212e-02, -1.4976e-02,  1.8037e-02,  2.9811e-02, -1.7707e-03],\n",
       "                        [-3.0941e-02, -4.1249e-03,  2.7648e-02,  9.1441e-05, -9.9904e-03],\n",
       "                        [ 1.8077e-02, -3.1227e-02,  9.7121e-03,  2.4223e-02, -1.3281e-04],\n",
       "                        [-3.4460e-02,  2.3203e-02, -6.2497e-03, -2.3804e-02, -2.7515e-02],\n",
       "                        [ 3.2061e-02,  2.6311e-02, -3.4847e-02, -2.5026e-02, -2.7410e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.0565e-02,  3.2575e-02, -3.1398e-02, -2.1027e-02, -1.0174e-02],\n",
       "                        [-3.1698e-03,  2.1584e-02, -1.3568e-02,  2.9512e-02, -2.2584e-02],\n",
       "                        [ 4.9850e-03, -4.9612e-03,  1.2845e-02,  1.1849e-02,  2.0516e-02],\n",
       "                        [ 1.0548e-02,  1.1557e-02,  1.0748e-02, -3.0551e-02,  2.8385e-02],\n",
       "                        [ 6.7309e-03, -3.5071e-02,  1.3195e-02, -1.0784e-02, -1.3362e-02]],\n",
       "              \n",
       "                       [[ 5.5073e-03,  1.3478e-02, -2.7400e-02, -7.2832e-03,  2.1729e-03],\n",
       "                        [-3.3063e-02,  2.8361e-02,  1.1249e-02,  2.5912e-02, -2.7563e-02],\n",
       "                        [-1.4415e-02, -2.5628e-02, -2.0783e-02,  2.5809e-02,  2.0449e-02],\n",
       "                        [ 2.2610e-02, -1.3387e-02, -2.0167e-02,  3.2302e-02,  3.1036e-02],\n",
       "                        [-2.4913e-02, -1.3171e-03, -4.4154e-03,  1.7574e-02,  7.7285e-03]],\n",
       "              \n",
       "                       [[-2.2610e-02, -2.2626e-02,  1.7125e-02,  1.4075e-02,  1.8090e-02],\n",
       "                        [ 2.1519e-02, -7.4838e-03,  1.1048e-02,  2.7644e-02,  2.2429e-02],\n",
       "                        [ 1.3360e-02, -9.8788e-03,  4.0257e-03,  8.0432e-04,  1.7940e-02],\n",
       "                        [-2.9491e-02, -1.5947e-02,  2.7690e-02,  9.0562e-06,  3.3895e-02],\n",
       "                        [ 2.1486e-02,  1.3432e-02,  3.4632e-02, -2.1342e-02,  1.4505e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.7554e-03,  2.4958e-02, -1.8968e-02,  8.7304e-03,  2.2037e-02],\n",
       "                        [-3.3219e-02,  2.9195e-02,  1.4101e-02, -2.6959e-02, -2.2583e-03],\n",
       "                        [ 1.6472e-02,  3.1138e-02,  1.7331e-02,  3.1524e-02, -2.7871e-03],\n",
       "                        [ 2.7491e-02,  1.2444e-03, -3.2536e-02,  4.4070e-03, -1.0498e-02],\n",
       "                        [ 2.1496e-02,  6.1953e-03,  1.6307e-02, -1.9352e-03,  1.2181e-02]],\n",
       "              \n",
       "                       [[ 2.5531e-02, -2.5377e-02, -1.5213e-02, -2.7147e-02,  2.9684e-02],\n",
       "                        [ 4.5762e-03, -2.0581e-02, -1.4533e-02,  2.2970e-02,  1.0837e-02],\n",
       "                        [ 2.2715e-02, -3.1703e-02, -2.8868e-02,  8.0688e-03, -2.9848e-02],\n",
       "                        [ 2.1746e-02, -1.1451e-02,  8.7061e-03,  2.4530e-02,  2.9695e-02],\n",
       "                        [-1.7731e-02, -3.1711e-02, -1.4775e-03, -2.7318e-02,  2.9782e-02]],\n",
       "              \n",
       "                       [[ 5.7166e-03, -4.6297e-03, -9.8798e-03, -1.0706e-02, -2.4379e-02],\n",
       "                        [-3.2648e-02,  1.2768e-02,  2.2441e-03, -2.7059e-02, -1.2851e-02],\n",
       "                        [ 1.4782e-02,  9.4122e-03,  1.4809e-02, -2.6946e-02,  1.0632e-02],\n",
       "                        [-1.0548e-02,  3.3025e-02, -2.1930e-02, -1.6560e-02, -1.1906e-02],\n",
       "                        [-3.1751e-02,  1.3901e-02,  8.9451e-03, -2.3018e-02,  2.7767e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.6635e-02,  3.0569e-02, -2.3676e-02, -1.6049e-02,  9.8934e-03],\n",
       "                        [ 1.4818e-02, -3.2445e-03,  1.4112e-02, -1.2042e-03, -1.5235e-02],\n",
       "                        [-1.5835e-02, -9.2206e-03, -9.0885e-03,  1.3400e-02, -9.3213e-03],\n",
       "                        [-3.2413e-02,  3.1031e-02, -1.4408e-02, -1.1130e-02,  2.9756e-02],\n",
       "                        [ 7.0365e-03,  3.1970e-02, -1.0323e-02,  1.9950e-02, -1.7046e-02]],\n",
       "              \n",
       "                       [[-2.0915e-02, -2.5142e-02,  2.7551e-02, -9.2203e-03,  1.1338e-02],\n",
       "                        [ 8.8168e-03,  2.2425e-02,  2.0211e-02, -2.1429e-02,  4.6121e-03],\n",
       "                        [ 1.9825e-02, -1.5085e-02, -2.0873e-02, -3.2973e-03, -3.4204e-02],\n",
       "                        [ 1.2655e-02, -1.4866e-02,  1.3376e-02,  2.9042e-02,  2.1619e-02],\n",
       "                        [-3.0871e-02, -2.1304e-02, -1.6398e-02,  2.4441e-02, -3.1728e-02]],\n",
       "              \n",
       "                       [[-9.4842e-03,  5.8508e-03,  3.1041e-02, -1.0417e-02,  5.6794e-03],\n",
       "                        [-2.1030e-02, -2.9929e-02, -1.0300e-02,  8.5952e-04, -1.8207e-02],\n",
       "                        [-1.8375e-02,  2.6712e-02, -8.3411e-03,  3.5021e-02,  7.3608e-03],\n",
       "                        [ 2.8233e-02, -1.1478e-02,  2.0859e-02,  1.8545e-03, -2.5401e-02],\n",
       "                        [ 3.1434e-03, -2.3787e-02,  3.3267e-03, -1.8920e-02,  8.3294e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.2411e-02, -3.8162e-03, -2.9645e-02,  2.5710e-02, -2.9212e-02],\n",
       "                        [ 1.0655e-02, -2.3520e-02,  2.1830e-02,  4.1026e-04, -1.5263e-02],\n",
       "                        [-2.3413e-02,  1.9863e-02,  6.2548e-03,  2.5289e-02,  3.1724e-02],\n",
       "                        [-1.2561e-02, -3.3893e-03,  3.4691e-03,  1.0083e-02, -1.0190e-03],\n",
       "                        [ 3.9444e-03, -8.9760e-03, -2.8321e-02,  1.3352e-03, -1.2931e-03]],\n",
       "              \n",
       "                       [[-1.5773e-03, -1.7362e-02,  2.9302e-02, -2.1671e-02, -1.4936e-02],\n",
       "                        [-3.3434e-03, -1.4303e-02, -3.4680e-02, -1.6563e-02, -2.7692e-02],\n",
       "                        [-3.0550e-02,  1.8209e-02,  1.4379e-02, -7.4282e-04,  3.2622e-02],\n",
       "                        [-2.3040e-02, -2.8910e-03, -2.1602e-02, -1.0730e-02, -5.8860e-03],\n",
       "                        [-2.9909e-02,  4.2256e-03,  1.4228e-02, -2.6174e-02,  4.9699e-03]],\n",
       "              \n",
       "                       [[-1.4508e-02, -1.6610e-02,  3.1742e-02,  1.8084e-02, -1.6195e-02],\n",
       "                        [ 9.9232e-03, -2.6096e-02,  2.9367e-02, -2.7743e-02, -3.3741e-02],\n",
       "                        [-1.2601e-03, -9.8694e-03, -2.0802e-02, -1.1457e-02, -1.2715e-02],\n",
       "                        [ 2.1826e-02,  2.5831e-02, -6.9275e-03,  1.6515e-02,  2.9705e-02],\n",
       "                        [ 2.7497e-03, -3.0967e-02,  3.1902e-02, -2.4882e-02,  8.3602e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.7075e-02, -1.8746e-02,  1.0497e-02, -1.2485e-02, -3.9681e-03],\n",
       "                        [-3.3854e-02, -1.3040e-02, -2.8741e-02, -1.8206e-03,  2.7808e-02],\n",
       "                        [-2.1347e-03,  1.2503e-02,  1.1956e-02, -3.1581e-02,  2.4535e-02],\n",
       "                        [ 2.2478e-02,  2.0849e-02,  3.1898e-02, -1.2604e-02,  3.7732e-03],\n",
       "                        [-1.0199e-02, -2.3722e-02,  6.3830e-03, -3.4788e-02,  3.1466e-02]],\n",
       "              \n",
       "                       [[-3.0649e-02,  1.6366e-02,  9.5046e-03, -4.1708e-03, -3.1485e-02],\n",
       "                        [ 1.5530e-02, -3.3709e-02,  2.8402e-02,  1.9035e-02,  1.0044e-02],\n",
       "                        [-2.1060e-02,  2.5263e-02,  2.0801e-02,  1.3848e-03, -2.2717e-02],\n",
       "                        [ 2.4544e-02, -7.3109e-03, -1.7753e-03,  2.4287e-02, -3.1613e-02],\n",
       "                        [ 2.3512e-02, -2.2022e-02, -2.3114e-02, -9.3511e-03,  3.3059e-02]],\n",
       "              \n",
       "                       [[ 1.7854e-02, -1.3691e-02,  2.6020e-02, -3.7759e-03, -3.4862e-02],\n",
       "                        [-2.2991e-02,  5.5706e-03,  3.5538e-03, -2.4625e-02,  1.2586e-02],\n",
       "                        [-4.5639e-03,  1.6063e-02,  3.1500e-02,  4.5396e-03, -1.8067e-02],\n",
       "                        [ 7.7482e-03,  2.9699e-02,  2.1619e-03,  2.8121e-02,  1.0387e-02],\n",
       "                        [-1.1392e-02, -1.4315e-02, -2.7461e-02,  2.5167e-02, -1.4807e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 5.0060e-03,  5.0172e-03,  2.2462e-02,  1.2037e-02,  1.0474e-03],\n",
       "                        [-2.8299e-02, -9.1624e-04, -2.6017e-02, -4.5086e-03,  1.6317e-02],\n",
       "                        [-1.3357e-03,  3.3867e-02, -5.9393e-03,  1.7843e-02, -1.6264e-02],\n",
       "                        [-7.3630e-03,  8.4548e-03, -2.9229e-02, -3.2796e-02,  1.6542e-02],\n",
       "                        [ 2.1635e-02, -1.9064e-02, -1.4278e-02,  1.8320e-02, -5.7560e-03]],\n",
       "              \n",
       "                       [[-1.1075e-02,  1.8692e-02, -7.0045e-03, -1.2526e-02, -6.2933e-03],\n",
       "                        [-3.4757e-02, -1.1966e-02, -2.6064e-04,  2.7671e-02,  2.6097e-02],\n",
       "                        [-4.0062e-03,  2.4022e-02,  1.1637e-02, -7.2735e-03, -2.3343e-02],\n",
       "                        [-1.8571e-02,  2.0576e-02,  3.3886e-02,  1.1206e-02, -1.7185e-02],\n",
       "                        [-2.6641e-02, -1.3942e-02,  3.2731e-03,  1.4921e-02,  1.2959e-02]],\n",
       "              \n",
       "                       [[ 2.1736e-02, -4.6580e-03,  2.5669e-02, -2.6789e-02,  2.9384e-02],\n",
       "                        [ 2.8226e-02,  4.2993e-03, -2.9045e-02, -2.6730e-02, -3.3561e-02],\n",
       "                        [ 5.2220e-03,  1.7777e-02,  1.4276e-02, -1.6063e-02, -1.2450e-03],\n",
       "                        [-1.7515e-02, -2.6264e-02, -1.4427e-02,  1.1915e-02,  1.7235e-02],\n",
       "                        [ 2.9327e-02, -2.2830e-02, -1.1258e-02, -2.7424e-02, -9.8252e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.0423e-02,  6.5726e-03,  2.6878e-02,  7.8468e-03, -3.4514e-03],\n",
       "                        [-1.7755e-03, -1.8111e-02,  1.8448e-02,  2.4708e-02, -1.4736e-02],\n",
       "                        [ 2.9453e-02, -3.3382e-02,  1.2020e-02,  3.3781e-02,  2.8014e-02],\n",
       "                        [ 2.6360e-02, -1.5698e-02, -6.8580e-03,  2.4950e-02,  1.0334e-02],\n",
       "                        [-3.4235e-02,  1.3599e-02, -5.8376e-03,  3.3202e-02, -1.8143e-02]],\n",
       "              \n",
       "                       [[-2.4981e-02,  1.6826e-02, -1.3437e-02,  3.2470e-02, -1.2711e-02],\n",
       "                        [ 1.0508e-02, -1.2559e-02,  2.4866e-02,  2.4324e-02, -3.2093e-03],\n",
       "                        [-6.4983e-03, -1.4134e-02, -2.5887e-02,  2.3661e-02,  2.8640e-02],\n",
       "                        [ 1.1061e-02,  4.1283e-04,  2.0811e-02,  1.0591e-02, -2.6912e-02],\n",
       "                        [ 2.0429e-02,  3.3660e-02, -1.2891e-02,  2.0549e-02, -5.3880e-03]],\n",
       "              \n",
       "                       [[ 5.8183e-03, -1.3257e-02, -3.0510e-03,  3.5286e-02, -1.1423e-03],\n",
       "                        [-1.8324e-02,  3.0959e-02, -2.8698e-02, -2.2847e-02, -2.0533e-02],\n",
       "                        [-2.9929e-02, -1.3619e-02,  6.6820e-03, -1.1497e-02,  9.6498e-03],\n",
       "                        [ 2.5975e-02,  9.0490e-03, -1.8453e-03, -3.0367e-02, -3.3677e-02],\n",
       "                        [-1.9529e-02,  2.0710e-02,  5.0038e-03, -3.1940e-02,  1.8986e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.1496e-03,  3.0558e-02,  6.2058e-03,  1.4405e-02,  2.0500e-02],\n",
       "                        [ 3.9317e-03,  3.0272e-02, -1.1020e-03, -3.3230e-02,  3.0582e-02],\n",
       "                        [ 2.2466e-02, -6.8195e-03, -1.8804e-02, -1.3336e-03,  2.2967e-02],\n",
       "                        [ 1.7637e-02,  2.2047e-02,  1.8021e-02,  7.1267e-04, -3.4037e-02],\n",
       "                        [ 1.4163e-02,  9.2595e-03, -1.9513e-02, -1.8534e-03,  2.4246e-02]],\n",
       "              \n",
       "                       [[ 2.7335e-02,  1.6523e-02,  1.1471e-02,  1.8835e-02, -2.0240e-02],\n",
       "                        [-1.4316e-02,  2.7197e-02,  1.1821e-02, -1.2805e-02,  2.5261e-02],\n",
       "                        [-3.1373e-02,  2.5690e-02,  1.9895e-02, -2.7174e-02, -6.7178e-04],\n",
       "                        [-1.7658e-02, -2.3724e-02, -1.9854e-02,  2.3774e-02,  3.0946e-02],\n",
       "                        [ 2.1491e-03,  2.8404e-02,  2.0969e-02,  2.4451e-02,  3.0226e-02]],\n",
       "              \n",
       "                       [[ 9.5167e-03, -3.4483e-02,  2.3395e-02,  1.0564e-02,  1.6799e-02],\n",
       "                        [ 3.2045e-02, -2.2503e-02,  1.6860e-02, -1.3014e-02,  9.4105e-03],\n",
       "                        [ 3.1903e-02,  2.4091e-02, -5.8590e-03,  3.3905e-02,  3.1496e-02],\n",
       "                        [-7.1634e-03, -1.1778e-02, -2.2175e-02, -1.8790e-03, -2.2195e-02],\n",
       "                        [-1.9911e-02,  7.0790e-03, -3.1700e-02,  2.5287e-02, -8.9626e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.4028e-02, -3.5108e-02, -2.7558e-02,  2.7318e-02, -1.5911e-02],\n",
       "                        [-5.3912e-03, -8.6890e-04, -1.2251e-03, -6.7470e-03,  1.2060e-02],\n",
       "                        [-1.5686e-02,  1.5508e-02, -1.8144e-02, -1.1645e-02, -1.8455e-02],\n",
       "                        [ 1.8525e-02,  1.2454e-02, -1.2954e-02,  2.6347e-02, -4.1293e-03],\n",
       "                        [ 3.0407e-02,  3.5033e-02, -3.0089e-02, -3.1440e-02, -2.7262e-02]],\n",
       "              \n",
       "                       [[-2.8637e-02, -9.7371e-03, -8.9015e-03, -4.4869e-03,  2.0103e-02],\n",
       "                        [ 8.8638e-03, -2.5404e-02, -2.8603e-02,  3.0421e-02, -1.0894e-02],\n",
       "                        [ 3.3675e-02,  9.1577e-03,  1.7767e-03, -5.4672e-04, -2.6066e-02],\n",
       "                        [ 1.1016e-02, -2.2925e-02,  1.6341e-03,  7.7270e-04, -3.4256e-02],\n",
       "                        [-3.5025e-02, -7.4883e-03,  1.7061e-02,  2.1005e-02, -2.8140e-02]],\n",
       "              \n",
       "                       [[-2.0939e-02, -1.0689e-02,  1.9067e-02, -2.9377e-02, -1.2524e-02],\n",
       "                        [-8.6401e-03,  3.2779e-03, -2.8566e-02, -1.5373e-02,  2.0345e-02],\n",
       "                        [ 9.8528e-03, -1.9419e-02, -1.8109e-02, -1.0010e-02, -2.8178e-02],\n",
       "                        [ 1.2279e-03, -2.4761e-02,  6.6784e-03, -1.8972e-02, -2.6652e-02],\n",
       "                        [-1.3693e-02,  3.5138e-02,  2.8539e-02,  1.8081e-02,  6.0351e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.1775e-02,  1.9023e-02, -8.7613e-03, -2.8927e-02, -1.2492e-02],\n",
       "                        [ 2.5442e-02, -2.7336e-03,  1.7961e-02,  3.0628e-02, -2.6174e-02],\n",
       "                        [ 5.2850e-03,  2.3501e-02,  1.2779e-02, -4.2664e-03,  2.4055e-02],\n",
       "                        [ 3.4978e-02,  2.4850e-02,  3.3947e-02, -9.2394e-03,  2.9876e-02],\n",
       "                        [-1.5080e-02, -1.1566e-02,  2.8571e-02,  1.8952e-03, -2.7838e-02]],\n",
       "              \n",
       "                       [[ 2.0237e-02, -1.6234e-02, -3.0583e-02, -1.9874e-02, -2.7235e-02],\n",
       "                        [ 6.9181e-03,  1.9409e-02,  1.6664e-02, -5.5674e-03, -2.7410e-02],\n",
       "                        [ 1.1718e-02,  1.7848e-02,  6.0809e-03, -3.5093e-02, -1.3415e-02],\n",
       "                        [-1.6263e-02,  8.0574e-03, -2.9509e-02, -8.0398e-03,  1.1278e-03],\n",
       "                        [ 3.3120e-02,  2.2363e-02, -1.6604e-03,  2.9395e-02,  2.7825e-02]],\n",
       "              \n",
       "                       [[-2.0363e-02,  4.7903e-03, -2.5429e-02,  1.0847e-02, -2.9462e-02],\n",
       "                        [-3.5341e-02,  2.5181e-02,  3.2721e-02, -1.4655e-03,  1.4279e-02],\n",
       "                        [ 2.6986e-02,  3.3062e-02, -2.1708e-03, -6.5801e-03, -3.3962e-02],\n",
       "                        [-2.1310e-02, -2.1079e-02, -5.0942e-04, -1.5594e-02,  2.0146e-02],\n",
       "                        [-1.9330e-02,  3.5140e-02, -1.1678e-02,  1.5903e-02,  1.8623e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.5474e-03,  1.2595e-02, -5.7813e-03,  3.0396e-02,  2.1347e-03],\n",
       "                        [ 1.6572e-02,  7.2098e-03,  9.5832e-03, -3.2017e-02, -2.0909e-02],\n",
       "                        [ 3.4548e-02, -2.1348e-02,  1.0295e-02, -2.4825e-02,  3.8884e-03],\n",
       "                        [-1.5548e-02,  2.1940e-02, -1.5875e-02,  3.2118e-02,  1.9760e-02],\n",
       "                        [-2.5389e-02, -4.6771e-03,  3.6136e-03, -8.5037e-03, -2.7831e-02]],\n",
       "              \n",
       "                       [[-9.9716e-03,  1.3606e-02, -1.8590e-02, -3.0624e-02, -1.1843e-02],\n",
       "                        [ 2.2966e-03, -2.6316e-02, -2.9196e-02,  2.5011e-02,  3.2911e-02],\n",
       "                        [-3.4294e-02, -2.8768e-02, -1.0424e-03,  1.5670e-02,  5.5647e-03],\n",
       "                        [ 8.1712e-03,  2.1326e-03, -1.0168e-02, -1.4986e-02,  9.6881e-03],\n",
       "                        [-2.8632e-02,  1.8007e-02,  1.7340e-03, -3.2111e-03, -2.0307e-02]],\n",
       "              \n",
       "                       [[ 2.5652e-02, -2.9138e-02,  1.8647e-02, -1.0373e-02,  1.6555e-02],\n",
       "                        [ 1.6586e-02, -1.1919e-03, -2.0455e-02, -2.3499e-02,  5.4656e-03],\n",
       "                        [ 1.8216e-02,  1.8413e-02,  3.3904e-03,  2.7810e-02, -2.3217e-02],\n",
       "                        [-1.5714e-02,  2.3608e-02,  4.0596e-03, -3.3875e-03, -3.3365e-02],\n",
       "                        [ 1.1100e-02, -3.2272e-02, -2.5030e-02, -2.5893e-02, -2.0754e-03]]]],\n",
       "                     device='cuda:0')),\n",
       "             ('conv_layer.3.bias',\n",
       "              tensor([-0.0347,  0.0038, -0.0094, -0.0321, -0.0085,  0.0123,  0.0068, -0.0049,\n",
       "                       0.0251,  0.0048,  0.0304,  0.0212, -0.0227, -0.0233,  0.0206,  0.0049,\n",
       "                      -0.0018, -0.0127,  0.0322,  0.0067, -0.0178, -0.0188, -0.0290,  0.0224,\n",
       "                      -0.0217, -0.0218,  0.0286, -0.0310, -0.0016,  0.0261, -0.0078, -0.0141,\n",
       "                      -0.0002,  0.0018,  0.0191, -0.0125,  0.0091, -0.0273, -0.0088,  0.0108,\n",
       "                       0.0101, -0.0243, -0.0201, -0.0193, -0.0222, -0.0060, -0.0014, -0.0249,\n",
       "                      -0.0295, -0.0288, -0.0105,  0.0273,  0.0024, -0.0120, -0.0195,  0.0190,\n",
       "                      -0.0238,  0.0247,  0.0244, -0.0351, -0.0010,  0.0178, -0.0288,  0.0304],\n",
       "                     device='cuda:0')),\n",
       "             ('fc_layer.0.weight',\n",
       "              tensor([[-0.0070,  0.0124, -0.0129,  ..., -0.0048,  0.0172, -0.0034],\n",
       "                      [ 0.0067,  0.0053,  0.0132,  ..., -0.0182,  0.0189,  0.0123],\n",
       "                      [-0.0248,  0.0192, -0.0074,  ..., -0.0142,  0.0223, -0.0138],\n",
       "                      ...,\n",
       "                      [ 0.0012,  0.0077, -0.0061,  ..., -0.0185, -0.0172, -0.0115],\n",
       "                      [ 0.0110, -0.0146,  0.0207,  ..., -0.0045, -0.0096, -0.0092],\n",
       "                      [-0.0018,  0.0226, -0.0086,  ...,  0.0127,  0.0049, -0.0111]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc_layer.0.bias',\n",
       "              tensor([-2.0495e-02, -8.9741e-03,  1.5264e-03, -1.3152e-02, -6.0090e-03,\n",
       "                      -1.1394e-02, -1.1261e-02, -1.2544e-02, -1.8224e-02,  2.3146e-02,\n",
       "                       1.2315e-02, -4.8055e-03,  8.2742e-03,  1.1405e-02,  4.0811e-03,\n",
       "                       2.3624e-02,  1.0993e-02,  8.7000e-03, -1.4754e-02, -2.2772e-02,\n",
       "                       6.6123e-03,  1.5462e-02, -1.8292e-02,  1.5762e-02, -2.4377e-02,\n",
       "                      -2.1598e-02,  4.1072e-03, -2.3366e-02,  2.3411e-02,  1.0475e-02,\n",
       "                       5.5800e-03, -1.5611e-02,  9.4184e-03,  9.2925e-03, -2.3241e-02,\n",
       "                       1.2080e-02, -1.0130e-03, -1.8812e-02,  3.6830e-05,  1.4023e-02,\n",
       "                      -2.2169e-02, -7.4436e-03,  6.5309e-03,  1.8296e-03, -8.9700e-03,\n",
       "                       7.6533e-03, -2.1902e-02,  7.9522e-03, -1.8926e-02, -2.9014e-04,\n",
       "                       5.6205e-03,  1.5046e-03, -2.0442e-02,  7.4313e-03, -1.5447e-02,\n",
       "                      -3.3127e-03, -1.7359e-02, -1.8795e-02, -1.1692e-02, -9.2435e-03,\n",
       "                      -5.6360e-03, -4.2641e-03,  2.4368e-02, -9.2848e-03,  8.6062e-03,\n",
       "                      -8.9782e-03, -2.1065e-02, -1.1167e-02, -1.7226e-02,  8.6294e-03,\n",
       "                      -1.6604e-02, -8.7701e-03,  1.3138e-02, -2.2644e-03, -1.6567e-02,\n",
       "                       6.7135e-03,  1.0815e-03,  1.6449e-02, -6.0060e-03, -1.4933e-03,\n",
       "                      -1.4521e-02,  2.4750e-02, -1.2693e-03, -1.3385e-02, -6.4325e-03,\n",
       "                       9.3126e-03,  1.8902e-02,  2.1678e-02,  1.5572e-02, -2.3952e-02,\n",
       "                      -2.3175e-02,  5.2103e-03, -7.9165e-04,  1.5956e-02,  1.8103e-02,\n",
       "                      -1.5047e-02,  2.1264e-02, -2.1303e-02, -3.1788e-03, -1.2969e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('fc_layer.2.weight',\n",
       "              tensor([[-0.0143, -0.0037,  0.0091,  0.0347,  0.0385,  0.0380,  0.0942, -0.0693,\n",
       "                        0.0839,  0.0661,  0.0520, -0.0574, -0.0767,  0.0206,  0.0323,  0.0762,\n",
       "                        0.0330, -0.0961,  0.0897,  0.0599,  0.0530, -0.0270,  0.0613, -0.0718,\n",
       "                        0.0551,  0.0429,  0.0378,  0.0020, -0.0842,  0.0379,  0.0233,  0.0945,\n",
       "                       -0.0116, -0.0534, -0.0664,  0.0285,  0.0319, -0.0885,  0.0290,  0.0067,\n",
       "                        0.0188, -0.0030,  0.0193,  0.0474, -0.0702,  0.0631, -0.0828,  0.0486,\n",
       "                        0.0408,  0.0361,  0.0774,  0.0862, -0.0135,  0.0723, -0.0972,  0.0882,\n",
       "                       -0.0032, -0.0705,  0.0964,  0.0439,  0.0696,  0.0984, -0.0417,  0.0150,\n",
       "                        0.0954, -0.0942, -0.0896, -0.0010,  0.0685, -0.0521,  0.0689,  0.0407,\n",
       "                        0.0971, -0.0600, -0.0237,  0.0394, -0.0591,  0.0120, -0.0285,  0.0253,\n",
       "                        0.0009, -0.0923,  0.0738, -0.0355,  0.0412, -0.0353, -0.0134,  0.0535,\n",
       "                        0.0684,  0.0645,  0.0726, -0.0547,  0.0297,  0.0599, -0.0204,  0.0509,\n",
       "                       -0.0475, -0.0559, -0.0987, -0.0335],\n",
       "                      [ 0.0151, -0.0572, -0.0806,  0.0739, -0.0759,  0.0918,  0.0386,  0.0850,\n",
       "                       -0.0457, -0.0149, -0.0440,  0.0471,  0.0447, -0.0557,  0.0302,  0.0227,\n",
       "                        0.0854,  0.0417,  0.0840, -0.0360,  0.0848, -0.0363,  0.0693,  0.0043,\n",
       "                        0.0537, -0.0134, -0.0411, -0.0174, -0.0590,  0.0970,  0.0721,  0.0316,\n",
       "                        0.0754,  0.0569, -0.0697,  0.0841,  0.0285,  0.0206,  0.0676,  0.0042,\n",
       "                        0.0883,  0.0643, -0.0558, -0.0297,  0.0388,  0.0923, -0.0085,  0.0429,\n",
       "                       -0.0114,  0.0692,  0.0703, -0.0802,  0.0979, -0.0874, -0.0085, -0.0622,\n",
       "                        0.0080,  0.0153, -0.0517,  0.0003, -0.0725, -0.0253, -0.0583, -0.0800,\n",
       "                       -0.0343,  0.0848, -0.0759,  0.0455, -0.0865, -0.0544,  0.0434,  0.0552,\n",
       "                        0.0914, -0.0312, -0.0266,  0.0798, -0.0836, -0.0915,  0.0420,  0.0054,\n",
       "                       -0.0630, -0.0455,  0.0852, -0.0567,  0.0743,  0.0188,  0.0606, -0.0715,\n",
       "                        0.0119,  0.0531, -0.0983,  0.0357,  0.0548,  0.0040, -0.0101, -0.0698,\n",
       "                        0.0678, -0.0175,  0.0533,  0.0278],\n",
       "                      [ 0.0788, -0.0536,  0.0287, -0.0380,  0.0897, -0.0798,  0.0231, -0.0168,\n",
       "                       -0.0852, -0.0880,  0.0209, -0.0625, -0.0086,  0.0538, -0.0248,  0.0060,\n",
       "                        0.0269,  0.0978, -0.0690,  0.0935,  0.0988, -0.0699,  0.0421,  0.0436,\n",
       "                       -0.0841,  0.0804,  0.0443,  0.0916,  0.0811,  0.0194,  0.0408, -0.0657,\n",
       "                        0.0035, -0.0736, -0.0931, -0.0704,  0.0233,  0.0420, -0.0938, -0.0246,\n",
       "                       -0.0019,  0.0597, -0.0374,  0.0736, -0.0060,  0.0443,  0.0141, -0.0992,\n",
       "                        0.0932,  0.0536,  0.0464,  0.0867, -0.0424, -0.0746,  0.0698, -0.0595,\n",
       "                       -0.0850, -0.0014,  0.0047,  0.0772,  0.0392, -0.0984,  0.0579,  0.0354,\n",
       "                       -0.0957,  0.0999,  0.0724,  0.0151, -0.0947, -0.0335,  0.0281, -0.0212,\n",
       "                       -0.0918,  0.0004,  0.0810, -0.0475,  0.0783,  0.0447,  0.0492,  0.0970,\n",
       "                       -0.0242, -0.0270, -0.0739,  0.0572, -0.0985,  0.0274, -0.0315,  0.0606,\n",
       "                        0.0925, -0.0425, -0.0362, -0.0885,  0.0968, -0.0495,  0.0586,  0.0861,\n",
       "                       -0.0514, -0.0511, -0.0377,  0.0731],\n",
       "                      [-0.0660,  0.0176,  0.0710,  0.0949,  0.0873, -0.0017, -0.0172, -0.0103,\n",
       "                       -0.0052,  0.0571, -0.0897,  0.0260, -0.0831,  0.0022,  0.0966,  0.0752,\n",
       "                        0.0502,  0.0349,  0.0259, -0.0485,  0.0342, -0.0297, -0.0933,  0.0449,\n",
       "                        0.0056, -0.0129, -0.0067, -0.0534, -0.0622, -0.0396,  0.0747,  0.0395,\n",
       "                        0.0968,  0.0783,  0.0414,  0.0949,  0.0417,  0.0977,  0.0345, -0.0240,\n",
       "                        0.0930, -0.0335, -0.0790, -0.0490, -0.0819, -0.0209,  0.0514, -0.0027,\n",
       "                       -0.0945,  0.0803,  0.0971,  0.0063, -0.0590, -0.0370,  0.0984,  0.0006,\n",
       "                        0.0080, -0.0611,  0.0607, -0.0071, -0.0216, -0.0127, -0.0733, -0.0367,\n",
       "                        0.0325,  0.0378,  0.0518,  0.0608,  0.0451, -0.0876,  0.0868,  0.0541,\n",
       "                        0.0136, -0.0943,  0.0126,  0.0201, -0.0230, -0.0476, -0.0053, -0.0039,\n",
       "                        0.0740, -0.0798,  0.0520,  0.0521, -0.0603, -0.0527,  0.0997,  0.0592,\n",
       "                        0.0176, -0.0363, -0.0246,  0.0720,  0.0829,  0.0760, -0.0543, -0.0809,\n",
       "                       -0.0656, -0.0079, -0.0464,  0.0882],\n",
       "                      [ 0.0212, -0.0646,  0.0309, -0.0645,  0.0358, -0.0420, -0.0512, -0.0515,\n",
       "                       -0.0113, -0.0756, -0.0790,  0.0654, -0.0782,  0.0695,  0.0020, -0.0613,\n",
       "                        0.0887, -0.0784,  0.0912, -0.0724, -0.0254, -0.0067,  0.0092,  0.0378,\n",
       "                       -0.0684,  0.0974,  0.0351, -0.0062,  0.0636, -0.0641, -0.0664, -0.0849,\n",
       "                        0.0469, -0.0223,  0.0234, -0.0730,  0.0013, -0.0262, -0.0265,  0.0611,\n",
       "                       -0.0142,  0.0567,  0.0820,  0.0149, -0.0052,  0.0808, -0.0940,  0.0471,\n",
       "                       -0.0188, -0.0685, -0.0918, -0.0639, -0.0347,  0.0943, -0.0313,  0.0454,\n",
       "                       -0.0659,  0.0781,  0.0922, -0.0465,  0.0742,  0.0430,  0.0874,  0.0135,\n",
       "                       -0.0977, -0.0432, -0.0172, -0.0997,  0.0551, -0.0493, -0.0429, -0.0362,\n",
       "                        0.0497, -0.0933, -0.0059,  0.0460,  0.0899,  0.0005,  0.0812,  0.0041,\n",
       "                       -0.0478, -0.0267, -0.0049, -0.0598,  0.0949, -0.0973,  0.0189, -0.0270,\n",
       "                       -0.0961,  0.0974, -0.0189, -0.0172, -0.0980, -0.0015, -0.0068,  0.0643,\n",
       "                        0.0131, -0.0730,  0.0239, -0.0248],\n",
       "                      [-0.0800,  0.0564,  0.0497, -0.0604,  0.0772, -0.0966, -0.0621,  0.0282,\n",
       "                       -0.0415,  0.0592,  0.0059, -0.0174, -0.0317,  0.0167, -0.0935, -0.0971,\n",
       "                       -0.0174,  0.0836,  0.0405,  0.0809, -0.0946, -0.0086, -0.0571, -0.0527,\n",
       "                        0.0231, -0.0071, -0.0537,  0.0805, -0.0750, -0.0608, -0.0270,  0.0112,\n",
       "                       -0.0923,  0.0280, -0.0458,  0.1000, -0.0338,  0.0745,  0.0186, -0.0979,\n",
       "                        0.0354,  0.0152, -0.0078, -0.0124, -0.0126, -0.0336, -0.0966, -0.0400,\n",
       "                       -0.0057, -0.0402, -0.0538,  0.0400,  0.0838,  0.0089, -0.0905, -0.0024,\n",
       "                        0.0626, -0.0908, -0.0171,  0.0245, -0.0384,  0.0250, -0.0910, -0.0563,\n",
       "                       -0.0215,  0.0980, -0.0465, -0.0475,  0.0096,  0.0244, -0.0375, -0.0015,\n",
       "                        0.0688,  0.0047,  0.0847, -0.0073, -0.0545, -0.0888,  0.0315,  0.0227,\n",
       "                       -0.0942, -0.0717, -0.0327, -0.0327,  0.0192,  0.0466,  0.0076, -0.0647,\n",
       "                       -0.0834, -0.0136,  0.0097, -0.0062,  0.0500,  0.0589, -0.0509, -0.0414,\n",
       "                        0.0035, -0.0982, -0.0135, -0.0363],\n",
       "                      [-0.0743, -0.0505, -0.0072, -0.0315,  0.0894, -0.0527,  0.0017, -0.0057,\n",
       "                       -0.0310, -0.0423, -0.0801, -0.0127, -0.0258, -0.0522, -0.0831,  0.0679,\n",
       "                       -0.0435, -0.0993, -0.0834,  0.0007, -0.0374,  0.0324,  0.0982,  0.0841,\n",
       "                       -0.0007,  0.0183,  0.0080, -0.0423,  0.0250, -0.0012,  0.0738,  0.0005,\n",
       "                        0.0837, -0.0706,  0.0986,  0.0633, -0.0245,  0.0663, -0.0050, -0.0109,\n",
       "                        0.0180,  0.0429, -0.0654,  0.0975,  0.0897,  0.0305, -0.0660, -0.0408,\n",
       "                        0.0449,  0.0919, -0.0373, -0.0154,  0.0981,  0.0192, -0.0971,  0.0529,\n",
       "                       -0.0114, -0.0004,  0.0951,  0.0837,  0.0623, -0.0011, -0.0656,  0.0036,\n",
       "                       -0.0879, -0.0191,  0.0742, -0.0751, -0.0380, -0.0293,  0.0169, -0.0800,\n",
       "                       -0.0533,  0.0686, -0.0343,  0.0318,  0.0714, -0.0326,  0.0364,  0.0871,\n",
       "                       -0.0369, -0.0771,  0.0629, -0.0775, -0.0974,  0.0903, -0.0051,  0.0775,\n",
       "                       -0.0022, -0.0310,  0.0974, -0.0962,  0.0044,  0.0953,  0.0278,  0.0787,\n",
       "                        0.0960,  0.0025,  0.0367, -0.0336],\n",
       "                      [-0.0686,  0.0343, -0.0649,  0.0535, -0.0520, -0.0198,  0.0579,  0.0973,\n",
       "                        0.0784, -0.0426, -0.0920,  0.0026,  0.0431, -0.0286, -0.0208,  0.0979,\n",
       "                        0.0291,  0.0470,  0.0158, -0.0794, -0.0038,  0.0127, -0.0873, -0.0707,\n",
       "                        0.0429, -0.0788,  0.0365,  0.0355,  0.0201,  0.0704, -0.0124,  0.0791,\n",
       "                        0.0455,  0.0064, -0.0064,  0.0823, -0.0573, -0.0377,  0.0427, -0.0457,\n",
       "                        0.0257, -0.0200, -0.0952, -0.0879, -0.0608,  0.0104, -0.0755, -0.0809,\n",
       "                       -0.0625,  0.0455, -0.0929,  0.0085,  0.0094, -0.0950, -0.0848,  0.0215,\n",
       "                        0.0142, -0.0914,  0.0821,  0.0976,  0.0276,  0.0876, -0.0574, -0.0312,\n",
       "                       -0.0223,  0.0509,  0.0264, -0.0221, -0.0953, -0.0297, -0.0748,  0.0482,\n",
       "                        0.0230, -0.0022, -0.0316, -0.0965, -0.0443, -0.0134, -0.0877, -0.0657,\n",
       "                       -0.0087,  0.0314,  0.0685,  0.0216, -0.0313, -0.0412,  0.0184,  0.0421,\n",
       "                       -0.0255,  0.0215,  0.0206,  0.0669,  0.0897,  0.0505, -0.0203,  0.0865,\n",
       "                        0.0111, -0.0272, -0.0231, -0.0400],\n",
       "                      [-0.0716,  0.0554,  0.0609, -0.0037,  0.0284,  0.0509,  0.0667,  0.0114,\n",
       "                        0.0604,  0.0050,  0.0166,  0.0950,  0.0303,  0.0136, -0.0374,  0.0490,\n",
       "                       -0.0109, -0.0433, -0.0367,  0.0458,  0.0664,  0.0486, -0.0624, -0.0160,\n",
       "                        0.0701, -0.0379, -0.0041,  0.0170,  0.0354,  0.0012, -0.0445,  0.0319,\n",
       "                       -0.0114,  0.0928,  0.0554,  0.0525,  0.0304,  0.0187,  0.0943,  0.0295,\n",
       "                        0.0999, -0.0832, -0.0731,  0.0584, -0.0597,  0.0015,  0.0978, -0.0279,\n",
       "                        0.0643,  0.0723,  0.0588,  0.0626, -0.0930, -0.0102,  0.0169,  0.0167,\n",
       "                        0.0286,  0.0166,  0.0980,  0.0064, -0.0924, -0.0832, -0.0421, -0.0332,\n",
       "                        0.0227, -0.0281, -0.0460, -0.0481,  0.0093, -0.0211,  0.0081, -0.0460,\n",
       "                        0.0588, -0.0398,  0.0400, -0.0224, -0.0563, -0.0357,  0.0539, -0.0442,\n",
       "                        0.0856, -0.0457,  0.0859, -0.0926,  0.0693,  0.0296, -0.0887,  0.0357,\n",
       "                       -0.0446,  0.0140, -0.0910,  0.0367, -0.0092, -0.0127,  0.0870,  0.0475,\n",
       "                       -0.0327, -0.0209,  0.0650, -0.0300],\n",
       "                      [-0.0055,  0.0372, -0.0109, -0.0059,  0.0021,  0.0535, -0.0280,  0.0783,\n",
       "                       -0.0725, -0.0978,  0.0470,  0.0818,  0.0440, -0.0152,  0.0062, -0.0363,\n",
       "                       -0.0543, -0.0308,  0.0192,  0.0219, -0.0210, -0.0282,  0.0923,  0.0065,\n",
       "                        0.0931, -0.0557,  0.0456,  0.0950,  0.0863,  0.0977, -0.0325, -0.0182,\n",
       "                        0.0673, -0.0311,  0.0151, -0.0055,  0.0379, -0.0774,  0.0283, -0.0513,\n",
       "                       -0.0125,  0.0615, -0.0039,  0.0249,  0.0692,  0.0765, -0.0250, -0.0298,\n",
       "                       -0.0041, -0.0618,  0.0315, -0.0211,  0.0984,  0.0025, -0.0426, -0.0832,\n",
       "                        0.0134,  0.0962,  0.0715,  0.0281, -0.0795, -0.0411,  0.0628,  0.0407,\n",
       "                        0.0435,  0.0293, -0.0653,  0.0068,  0.0140, -0.0896, -0.0394, -0.0970,\n",
       "                       -0.0411, -0.0858, -0.0639,  0.0816, -0.0061, -0.0781, -0.0032, -0.0489,\n",
       "                       -0.0505,  0.0795,  0.0881,  0.0131, -0.0957, -0.0674,  0.0070,  0.0207,\n",
       "                        0.0582,  0.0643, -0.0374, -0.0769, -0.0865,  0.0627, -0.0861, -0.0072,\n",
       "                        0.0843, -0.0768, -0.0314,  0.0037]], device='cuda:0')),\n",
       "             ('fc_layer.2.bias',\n",
       "              tensor([-0.0393,  0.0842, -0.0608, -0.0521,  0.0652,  0.0221,  0.0267, -0.0135,\n",
       "                      -0.0507, -0.0039], device='cuda:0'))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class가 변경되거나 없어져도 불러올 수 있음. 최악의 경우에도 유추 가능.\n",
    "torch.load(\"sample2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95a760ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 물론 최종적으로는 Class가 있어야함.\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64*5*5, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 10)              \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer(x)\n",
    "        out = out.view(-1, 64*5*5)\n",
    "        out = self.fc_layer(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = CNN().cuda()\n",
    "model.load_state_dict(torch.load(\"sample2.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fee0e962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv_layer): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layer): Sequential(\n",
       "    (0): Linear(in_features=1600, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
